{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parameter as P\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCMF(nn.Module):\n",
    "    '''\n",
    "    Base class for Fully-Connected Matrix Factorization networks\n",
    "    '''\n",
    "    \n",
    "    def __init__ (self, N, M, D, D_, K, layers):\n",
    "        '''\n",
    "        variable definitions taken from paper: https://arxiv.org/pdf/1511.06443.pdf\n",
    "        \n",
    "        @param N:  Number of users\n",
    "        @param M:  Number of items\n",
    "        @param D:  size of latent-feature vectors\n",
    "        @param D_: num rows in latent-features matrices\n",
    "        @param K:  num cols in latent-feature matrices\n",
    "        \n",
    "        @param layers: list of hidden layer sizes; does not include input or output\n",
    "        '''\n",
    "        \n",
    "        assert (min(N,M,D,D_,K) > 0), \"Params must be nonzero and positive\"\n",
    "        assert (len(layers) > 0),     \"Must have nonzero hidden layers\"\n",
    "        \n",
    "        ########################################################################\n",
    "        \n",
    "        super(FCMF, self).__init__()\n",
    "        \n",
    "        self.N, self.M, self.D, self.D_, self.K = N, M, D, D_, K\n",
    "        \n",
    "        self.userLatentVectors = P.Parameter(torch.rand(N,D, requires_grad=True))\n",
    "        self.itemLatentVectors = P.Parameter(torch.rand(M,D, requires_grad=True))\n",
    "        \n",
    "        self.userLatentMatrices = P.Parameter(torch.rand(N,D_,K, requires_grad=True))\n",
    "        self.itemLatentMatrices = P.Parameter(torch.rand(M,D_,K, requires_grad=True))\n",
    "        \n",
    "        linear_inputs = [2*D + D_] + layers\n",
    "        linear_outputs = layers + [1]\n",
    "        \n",
    "        self.layers = nn.ModuleList([nn.Linear(i,o) for (i,o) in zip(linear_inputs, linear_outputs)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        @param x: let this be a tensor of size (X, 2): (user index, item index)\n",
    "        \n",
    "        WARNING: \n",
    "            - forward currently does not account for user/items outside of training data\n",
    "            - mitigations include returning smart averages    \n",
    "        '''        \n",
    "        userIndices, itemIndices = x[:,0].long(), x[:,1].long()\n",
    "                \n",
    "        userLatMats = self.userLatentMatrices[userIndices]\n",
    "        itemLatMats = self.itemLatentMatrices[itemIndices]\n",
    "        latentDotProducts = torch.sum(userLatMats * itemLatMats, dim=-1)        \n",
    "        \n",
    "        x = torch.hstack([\n",
    "            self.userLatentVectors[userIndices],\n",
    "            self.itemLatentVectors[itemIndices],\n",
    "            latentDotProducts\n",
    "        ])\n",
    "        \n",
    "        for l in self.layers[:-1]:\n",
    "            x = F.relu(l(x))\n",
    "        \n",
    "        # TODO: should last layer go through a sigmoid?\n",
    "        return self.layers[-1](x)\n",
    "    \n",
    "    def gradAll(self):\n",
    "        self._setGrads(True, True, True, True, True)\n",
    "    \n",
    "    def gradNetwork(self):\n",
    "        self._setGrads(False, False, False, False, True)\n",
    "\n",
    "    def gradLatent(self):\n",
    "        self._setGrads(True, True, True, True, False)\n",
    "\n",
    "    def _setGrads(self, userVec, itemVec, userMat, itemMat, net):\n",
    "        self.userLatentVectors.requires_grad_(userVec)\n",
    "        self.itemLatentVectors.requires_grad_(itemVec)\n",
    "        \n",
    "        self.userLatentMatrices.requires_grad_(userMat)\n",
    "        self.itemLatentMatrices.requires_grad_(itemMat)\n",
    "        \n",
    "        self.layers.requires_grad = net\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatches(mat, usersPerBatch=100):\n",
    "    '''\n",
    "    batchSize = min(N - start, usersPerBatch) * M\n",
    "    '''\n",
    "    N, M = mat.shape\n",
    "    \n",
    "    start = 0\n",
    "    while start < N:\n",
    "        batchSize = min(N - start, usersPerBatch) * M\n",
    "                \n",
    "        batch_x = torch.empty(batchSize, 2)\n",
    "        batch_y = torch.empty(batchSize, 1)\n",
    "        \n",
    "        for userId, ratings in enumerate(mat[start: start+N]):\n",
    "            for movieId, stars in enumerate(ratings):\n",
    "                \n",
    "                curId = userId * M + movieId\n",
    "                                \n",
    "                batch_x[curId][0] = userId\n",
    "                batch_x[curId][1] = movieId\n",
    "                batch_y[curId][0] = stars\n",
    "                    \n",
    "        start += N\n",
    "        \n",
    "        yield (batch_x, batch_y)\n",
    "        \n",
    "    \n",
    "\n",
    "def trainEpoch(opt, criterion, model, mat):\n",
    "    opt.zero_grad()\n",
    "    loss = 0\n",
    "    for batch_x, batch_y in getBatches(mat):\n",
    "        pred_y = model(batch_x)\n",
    "        loss += criterion(batch_y, pred_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 3, 1, 3],\n",
       "       [2, 3, 0, 5, 5],\n",
       "       [1, 1, 3, 3, 4],\n",
       "       [4, 1, 5, 2, 2],\n",
       "       [3, 3, 0, 0, 4]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numUsers = 5\n",
    "numItems = 5\n",
    "\n",
    "def randMat():\n",
    "    return np.random.randint(6, size=(numUsers, numItems))\n",
    "\n",
    "testMatrix = randMat()\n",
    "testMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1d8ef301cadb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFCMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumUsers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumItems\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-ff4e37fe0534>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, N, M, D, D_, K, layers)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserLatentVectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemLatentVectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'P' is not defined"
     ]
    }
   ],
   "source": [
    "fc3 = FCMF(numUsers, numItems ,2,2,1,[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Paper uses RMSE as objective and RMSProp optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(fc3.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEpoch(optimizer, criterion, fc3, testMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc3.gradLatent()\n",
    "trainEpoch(optimizer, criterion, fc3, randMat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc3.gradNetwork()\n",
    "trainEpoch(optimizer, criterion, fc3, randMat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc3.gradAll()\n",
    "trainEpoch(optimizer, criterion, fc3, randMat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userLatentVectors',\n",
       "  Parameter containing:\n",
       "  tensor([[0.6560, 1.2778],\n",
       "          [0.0103, 1.1705],\n",
       "          [0.0426, 0.8050],\n",
       "          [0.3098, 0.9659],\n",
       "          [0.4452, 0.7394]], requires_grad=True)),\n",
       " ('layers.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2738,  0.0099, -0.1069,  0.2414, -0.1543, -0.2926],\n",
       "          [-0.3537,  0.2577, -0.3879, -0.2134, -0.2290, -0.3225],\n",
       "          [ 0.1727,  0.7911,  0.7274,  0.3876,  0.5268,  0.8661],\n",
       "          [-0.3029, -0.2514, -0.2051,  0.0914,  0.0065, -0.4467],\n",
       "          [-0.3514, -0.2216, -0.1388, -0.4857,  0.3218,  0.0411]],\n",
       "         requires_grad=True)),\n",
       " ('layers.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.2979, -0.3259,  0.4670,  0.1606,  0.3767], requires_grad=True)),\n",
       " ('layers.1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1442, -0.1540,  0.8235, -0.3451, -0.0610]], requires_grad=True)),\n",
       " ('layers.1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.7270], requires_grad=True))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fc3.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
